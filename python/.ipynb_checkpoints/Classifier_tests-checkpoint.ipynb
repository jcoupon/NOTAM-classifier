{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # import all the necessary libraries\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn import discriminant_analysis\n",
    "from sklearn import svm\n",
    "\n",
    "# options\n",
    "data_dir = os.getenv(\"HOME\")+'/data/NOTAM-classifier'\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# aestetics\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rc('pdf',fonttype=42)\n",
    "sns.mpl.rc('figure', figsize = (10, 8))\n",
    "sns.set_context('notebook', font_scale=1.8, rc={'lines.linewidth': 2.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTAMs_df = pd.read_csv(data_dir+'/NOTAMS.csv', sep=',').set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(NOTAMs_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NOTAMs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'scope', 'FIR_12', 'high_min_alt', \n",
    "    'low_max_alt', 'diurnal_duration', \n",
    "    'long_text', 'small_radius', \n",
    "    'trafficind', 'code_23', \n",
    "    'n_locations', 'code_45']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding scope\n",
      "Encoding FIR_12\n",
      "Encoding high_min_alt\n",
      "Encoding low_max_alt\n",
      "Encoding diurnal_duration\n",
      "Encoding long_text\n",
      "Encoding small_radius\n",
      "Encoding trafficind\n",
      "Encoding code_23\n",
      "Encoding n_locations\n",
      "Encoding code_45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  5.,  84.,   0., ..., 132.,   0.,  10.],\n",
       "       [  5.,  76.,   1., ..., 148.,   1.,  38.],\n",
       "       [  5.,  76.,   1., ..., 148.,   1.,  38.],\n",
       "       ...,\n",
       "       [  4.,  63.,   0., ...,  56.,   4.,  25.],\n",
       "       [  4.,   8.,   0., ...,  56.,   0.,  25.],\n",
       "       [  0.,  57.,   0., ...,  95.,   0.,  23.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "n_samples = len(NOTAMs_df)\n",
    "n_features = len(features)\n",
    "X = np.zeros((n_samples, n_features))\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "for i,feature in enumerate(features):\n",
    "    print('Encoding {}'.format(feature))    \n",
    "    X[:, i] = le.fit_transform(NOTAMs_df[feature].astype(str))\n",
    "\n",
    "y = NOTAMs_df['supress']\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(X, y, classifier, prob=None, random_seed=20091982):\n",
    "    \"\"\" Run classifier and print\n",
    "    results\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(\n",
    "        X, y, test_size=0.20, random_state=random_seed)\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    if prob is not None:\n",
    "        y_pred = classifier.predict_proba(X_test)[:,0] < prob\n",
    "    else:\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        \n",
    " \n",
    "    N = len(y_test)\n",
    "    TP = np.sum((y_pred == y_test) & (y_test == 1))\n",
    "    TN = np.sum((y_pred == y_test) & (y_test == 0))\n",
    "    FP = np.sum((y_pred != y_test) & (y_pred == 1))\n",
    "    FN = np.sum((y_pred != y_test) & (y_pred == 0))\n",
    "\n",
    "    accuracy = (TP+TN)/N\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "\n",
    "    result_string = 'N={0}, TP={1}, TN={2}, FP={3}, FN={4}\\n'.format(N, TP, TN, FP, FN)\n",
    "    result_string += \\\n",
    "        'Precision: {0:.4f}, recall: {1:.4f}, accuracy: {2:.4f}'\\\n",
    "        .format(precision, recall, accuracy)\n",
    "\n",
    "    print(result_string)\n",
    "    \n",
    "    report = metrics.classification_report(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    print(report)\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "def get_feature_importances(cols, importances):\n",
    "    \n",
    "    count = 0\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    for i in indices:\n",
    "        print('{1}: {0:.2f}%'.format(\n",
    "            importances[i]*100.0, cols[i]))\n",
    "        count += 1\n",
    "        #if count == 10:\n",
    "        #    break\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=19710, TP=8083, TN=9734, FP=931, FN=962\n",
      "Precision: 0.8967, recall: 0.8936, accuracy: 0.9040\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91     10665\n",
      "          1       0.90      0.89      0.90      9045\n",
      "\n",
      "avg / total       0.90      0.90      0.90     19710\n",
      "\n",
      "N=19710, TP=6615, TN=10495, FP=170, FN=2430\n",
      "Precision: 0.9749, recall: 0.7313, accuracy: 0.8681\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.98      0.89     10665\n",
      "          1       0.97      0.73      0.84      9045\n",
      "\n",
      "avg / total       0.89      0.87      0.86     19710\n",
      "\n",
      "N=19710, TP=4927, TN=10611, FP=54, FN=4118\n",
      "Precision: 0.9892, recall: 0.5447, accuracy: 0.7883\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.99      0.84     10665\n",
      "          1       0.99      0.54      0.70      9045\n",
      "\n",
      "avg / total       0.84      0.79      0.77     19710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = classify(X, y, RandomForestClassifier(random_state=20091982), prob=0.5)\n",
    "\n",
    "# recall = 98%, reduce screened NOTAMs by 90%\n",
    "classifier = classify(X, y, RandomForestClassifier(random_state=20091982), prob=0.1)\n",
    "\n",
    "# recall = 99%, reduce screened NOTAMs by 80%\n",
    "classifier = classify(X, y, RandomForestClassifier(random_state=20091982), prob=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code_23: 21.59%\n",
      "FIR_12: 21.23%\n",
      "scope: 19.75%\n",
      "code_45: 16.95%\n",
      "low_max_alt: 13.25%\n",
      "trafficind: 2.08%\n",
      "long_text: 1.84%\n",
      "diurnal_duration: 1.25%\n",
      "high_min_alt: 0.85%\n",
      "n_locations: 0.67%\n",
      "small_radius: 0.53%\n"
     ]
    }
   ],
   "source": [
    "get_feature_importances(features, classifier.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98547, 421)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder()    \n",
    "X_one_hot = enc.fit_transform(X)\n",
    "\n",
    "X_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=19710, TP=5223, TN=10482, FP=183, FN=3822\n",
      "Precision: 0.9661, recall: 0.5774, accuracy: 0.7968\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.98      0.84     10665\n",
      "          1       0.97      0.58      0.72      9045\n",
      "\n",
      "avg / total       0.84      0.80      0.79     19710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# essentially recall = 100%, reduce screened NOTAMs by 60%\n",
    "classifier = classify(X_one_hot, y, LogisticRegression(), prob=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=19710, TP=1692, TN=10646, FP=19, FN=7353\n",
      "Precision: 0.9889, recall: 0.1871, accuracy: 0.6260\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      1.00      0.74     10665\n",
      "          1       0.99      0.19      0.31      9045\n",
      "\n",
      "avg / total       0.77      0.63      0.55     19710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# some more test\n",
    "classifier = classify(X_one_hot, y, LogisticRegression(), prob=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=19710, TP=7894, TN=9994, FP=671, FN=1151\n",
      "Precision: 0.9217, recall: 0.8727, accuracy: 0.9076\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.94      0.92     10665\n",
      "          1       0.92      0.87      0.90      9045\n",
      "\n",
      "avg / total       0.91      0.91      0.91     19710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = classify(X_one_hot, y, MLPClassifier(), prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=19710, TP=8083, TN=9734, FP=931, FN=962\n",
      "Precision: 0.8967, recall: 0.8936, accuracy: 0.9040\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91     10665\n",
      "          1       0.90      0.89      0.90      9045\n",
      "\n",
      "avg / total       0.90      0.90      0.90     19710\n",
      "\n",
      "N=19710, TP=8097, TN=9766, FP=899, FN=948\n",
      "Precision: 0.9001, recall: 0.8952, accuracy: 0.9063\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.92      0.91     10665\n",
      "          1       0.90      0.90      0.90      9045\n",
      "\n",
      "avg / total       0.91      0.91      0.91     19710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = classify(X, y, RandomForestClassifier(random_state=20091982), prob=0.5)\n",
    "classifier = classify(X_one_hot, y, RandomForestClassifier(random_state=20091982), prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=19710, TP=5217, TN=9892, FP=773, FN=3828\n",
      "Precision: 0.8710, recall: 0.5768, accuracy: 0.7666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.93      0.81     10665\n",
      "          1       0.87      0.58      0.69      9045\n",
      "\n",
      "avg / total       0.79      0.77      0.76     19710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = classify(X_one_hot, y, BernoulliNB(), prob=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=19710, TP=7844, TN=9805, FP=860, FN=1201\n",
      "Precision: 0.9012, recall: 0.8672, accuracy: 0.8954\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.92      0.90     10665\n",
      "          1       0.90      0.87      0.88      9045\n",
      "\n",
      "avg / total       0.90      0.90      0.90     19710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classifier = classify(X, y, GradientBoostingClassifier(), prob=0.01)\n",
    "classifier = classify(X, y, svm.SVC(probability=False), prob=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes time to train\n",
    "# classifier = classify(X, y, svm.SVC())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.24659881\n",
      "Iteration 2, loss = 0.20226820\n",
      "Iteration 3, loss = 0.19163974\n",
      "Iteration 4, loss = 0.18474149\n",
      "Iteration 5, loss = 0.18029736\n",
      "Iteration 6, loss = 0.17660244\n",
      "Iteration 7, loss = 0.17491304\n",
      "Iteration 8, loss = 0.17161727\n",
      "Iteration 9, loss = 0.17039928\n",
      "Iteration 10, loss = 0.16904896\n",
      "Iteration 11, loss = 0.16736087\n",
      "Iteration 12, loss = 0.16621319\n",
      "Iteration 13, loss = 0.16498497\n",
      "Iteration 14, loss = 0.16434805\n",
      "Iteration 15, loss = 0.16301117\n",
      "Iteration 16, loss = 0.16245633\n",
      "Iteration 17, loss = 0.16281371\n",
      "Iteration 18, loss = 0.16201198\n",
      "Iteration 19, loss = 0.16135211\n",
      "Iteration 20, loss = 0.16055302\n",
      "Iteration 21, loss = 0.16028648\n",
      "Iteration 22, loss = 0.16077473\n",
      "Iteration 23, loss = 0.15980274\n",
      "Iteration 24, loss = 0.15932235\n",
      "Iteration 25, loss = 0.15917991\n",
      "Iteration 26, loss = 0.15836582\n",
      "Iteration 27, loss = 0.15835138\n",
      "Iteration 28, loss = 0.15831309\n",
      "Iteration 29, loss = 0.15892939\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "N=19710, TP=7957, TN=9945, FP=720, FN=1088\n",
      "Precision: 0.9170, recall: 0.8797, accuracy: 0.9083\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.93      0.92     10665\n",
      "          1       0.92      0.88      0.90      9045\n",
      "\n",
      "avg / total       0.91      0.91      0.91     19710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = classify(\n",
    "    X_one_hot, y, \n",
    "    MLPClassifier(\n",
    "        hidden_layer_sizes=(200, 10), \n",
    "        learning_rate_init=0.01, \n",
    "        verbose=True), \n",
    "    prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
